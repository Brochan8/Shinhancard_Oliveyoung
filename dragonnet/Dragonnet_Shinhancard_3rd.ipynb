{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOE8/kW6fLOnxyect1kx/il"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"94FQgixOiug6"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","source":["# ==============================\n","# 1. 환경 설정\n","# ==============================\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","DATA_PATH = \"Shinhancard_data20251205_cleaned.csv\"  # CSV 파일 경로"],"metadata":{"id":"c5iapFPFiy4g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================\n","# 2. 데이터 로드 및 전처리\n","# ==============================\n","\n","# (1) CSV 읽기\n","df = pd.read_csv(DATA_PATH)\n","\n","# (2) 사용할 변수 정의\n","x_cols = [\n","    \"PERIOD_M\",         # 가입경과월수\n","    \"AVG_36_M\",         # 직전 3년간 월평균 결제액\n","    \"AVG_12_M\",         # 18년 1년간 월평균 결제액\n","    \"USE_CNT_18Y\",      # 18년 올리브영 이용건수\n","    \"USE_AMT_18Y1\",     # 18년 올리브영 총결제액\n","    \"CNT_18Y\",          # 18년 오퍼담은 횟수\n","    \"CNT_18Y_OLV\",      # 18년 오퍼담은 횟수(올리브영)\n","    \"MSG0\",             # 기본 프로모션\n","    \"MSG1\",             # 실험 프로모션 1\n","    \"MSG2\",             # 실험 프로모션 2\n","    \"MSG3\",             # 실험 프로모션 3\n","    \"MSG4\",             # 실험 프로모션 4\n","    \"MSG5\",             # 실험 프로모션 5\n","    \"Weekend\",          # 오퍼 전송 시 주말/주중 여부\n","    \"Badair\"            # 오퍼 전송 시 대기오염정도\n","]\n","\n","t_col = \"OFF_YN\"         # Treatment: 오퍼담기 여부(1: 오퍼담음 / 0: 오퍼담지 않음)\n","y_col = \"GAP_MIN1_USE\"   # Outcome: 오퍼 담은 이후 첫번째 올리브영 방문 지출액\n","\n","# (3) 필요한 컬럼만 남기기\n","cols_needed = x_cols + [t_col, y_col]\n","df = df[cols_needed].copy()\n","\n","# (4) 결측값 처리: 일단은 단순 dropna\n","df[cols_needed] = df[cols_needed].replace(r\"^\\s*$\", np.nan, regex=True) #공백문자열 처리\n","df = df.dropna(subset=cols_needed)\n","\n","# (5) X, T, Y 분리\n","X = df[x_cols].values.astype(np.float32)\n","t = df[t_col].values.astype(np.float32)\n","y = df[y_col].values.astype(np.float32)\n","\n","# (6) 연속형 변수만 표준화 (평균 0, 표준편차 1)\n","#    더미/범주형은 그대로 둠\n","continuous_cols = [\n","    \"PERIOD_M\",\n","    \"AVG_36_M\",\n","    \"AVG_12_M\",\n","    \"USE_CNT_18Y\",\n","    \"USE_AMT_18Y1\",\n","    \"CNT_18Y\",\n","    \"CNT_18Y_OLV\"\n","]\n","binary_cols = [\n","    \"MSG0\", \"MSG1\", \"MSG2\", \"MSG3\", \"MSG4\", \"MSG5\",\n","    \"Weekend\", \"Badair\"\n","]\n","\n","cont_idx = [x_cols.index(c) for c in continuous_cols]\n","\n","scaler = StandardScaler()\n","X_cont = scaler.fit_transform(X[:, cont_idx])\n","\n","# 표준화된 값으로 교체\n","X_scaled = X.copy()\n","X_scaled[:, cont_idx] = X_cont\n","\n","# (7) Train / Test split\n","X_train, X_test, t_train, t_test, y_train, y_test = train_test_split(\n","    X_scaled, t, y,\n","    test_size=0.2,\n","    random_state=RANDOM_SEED,\n","    stratify=(t > 0.5)  # treatment 비율 유지\n",")\n","\n","print(\"Train size:\", X_train.shape[0])\n","print(\"Test size:\", X_test.shape[0])"],"metadata":{"id":"Zhnpkge7iz_4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================\n","# 3. Dataset & DataLoader 정의\n","# ==============================\n","\n","class CausalDataset(Dataset):\n","    def __init__(self, X, t, y):\n","        self.X = torch.from_numpy(X).float()\n","        self.t = torch.from_numpy(t).float().unsqueeze(1)  # (N,1)\n","        self.y = torch.from_numpy(y).float().unsqueeze(1)  # (N,1)\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.t[idx], self.y[idx]\n","\n","batch_size = 256\n","\n","train_ds = CausalDataset(X_train, t_train, y_train)\n","test_ds  = CausalDataset(X_test,  t_test,  y_test)\n","\n","train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)"],"metadata":{"id":"J96paMhbi1ev"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================\n","# 4. DragonNet 모델 정의\n","# ==============================\n","\n","class DragonNet(nn.Module):\n","    def __init__(self, input_dim, hidden_shared=200, hidden_outcome=100):\n","        super(DragonNet, self).__init__()\n","        # Shared representation network\n","        self.shared = nn.Sequential(\n","            nn.Linear(input_dim, hidden_shared),\n","            nn.ReLU(),\n","            nn.Linear(hidden_shared, hidden_shared),\n","            nn.ReLU()\n","        )\n","\n","        # Propensity head (g(X) = P(T=1|X))\n","        self.propensity_head = nn.Sequential(\n","            nn.Linear(hidden_shared, hidden_shared // 2),\n","            nn.ReLU(),\n","            nn.Linear(hidden_shared // 2, 1),\n","            nn.Sigmoid()\n","        )\n","\n","        # Outcome head for T=0 (y0)\n","        self.outcome0_head = nn.Sequential(\n","            nn.Linear(hidden_shared, hidden_outcome),\n","            nn.ReLU(),\n","            nn.Linear(hidden_outcome, 1)\n","        )\n","\n","        # Outcome head for T=1 (y1)\n","        self.outcome1_head = nn.Sequential(\n","            nn.Linear(hidden_shared, hidden_outcome),\n","            nn.ReLU(),\n","            nn.Linear(hidden_outcome, 1)\n","        )\n","\n","    def forward(self, x):\n","        h = self.shared(x)\n","        p = self.propensity_head(h)  # (N,1)\n","        y0 = self.outcome0_head(h)   # (N,1)\n","        y1 = self.outcome1_head(h)   # (N,1)\n","        return y0, y1, p"],"metadata":{"id":"YQiuddzti4Iv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================\n","# 5. DragonNet 손실 함수 정의 (간단 TarReg 버전)\n","# ==============================\n","\n","def dragonnet_loss(y_true, t, y0_pred, y1_pred, p_pred,\n","                   alpha=1.0, beta=1.0):\n","    \"\"\"\n","    y_true : 실제 결과 (N,1)\n","    t      : 처리 여부 (N,1) 0 또는 1\n","    y0_pred, y1_pred : DragonNet의 결과 예측 (N,1)\n","    p_pred : 성향 점수 예측 P(T=1|X) (N,1)\n","    alpha, beta : 가중치 하이퍼파라미터\n","    \"\"\"\n","    # 관측된 처리에 해당하는 outcome 예측만 사용\n","    # y_pred = t * y1 + (1-t) * y0\n","    y_pred = t * y1_pred + (1.0 - t) * y0_pred\n","\n","    # 1) Outcome prediction loss (MSE)\n","    loss_y = nn.MSELoss()(y_pred, y_true)\n","\n","    # 2) Propensity loss (Binary Cross-Entropy)\n","    loss_t = nn.BCELoss()(p_pred, t)\n","\n","    # 3) Targeted Regularization (간단 버전)\n","    #   (t - p) * (y1 - y0)를 0에 가깝게 만들도록 하는 정규화\n","    #   논문에서는 더 정교하지만 여기서는 직관 위주의 구현\n","    tar_reg = torch.mean((t - p_pred) * (y1_pred - y0_pred))\n","\n","    loss = loss_y + alpha * loss_t + beta * (tar_reg ** 2)\n","    return loss, loss_y, loss_t, tar_reg"],"metadata":{"id":"IaCGS_Tsi6Rc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================\n","# 6. 모델 생성 및 학습 루프\n","# ==============================\n","\n","input_dim = X_train.shape[1]\n","model = DragonNet(input_dim=input_dim).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n","\n","epochs = 10\n","\n","for epoch in range(1, epochs + 1):\n","    model.train()\n","    running_loss = 0.0\n","    running_loss_y = 0.0\n","    running_loss_t = 0.0\n","\n","    for xb, tb, yb in train_loader:\n","        xb = xb.to(device)\n","        tb = tb.to(device).float()\n","        yb = yb.to(device)\n","\n","        optimizer.zero_grad()\n","        y0_pred, y1_pred, p_pred = model(xb)\n","        loss, loss_y, loss_t, tar_reg = dragonnet_loss(\n","            yb, tb, y0_pred, y1_pred, p_pred,\n","            alpha=1.0, beta=1.0\n","        )\n","        loss.backward()\n","        optimizer.step()\n","\n","        batch_size_cur = xb.size(0)\n","        running_loss   += loss.item()   * batch_size_cur\n","        running_loss_y += loss_y.item() * batch_size_cur\n","        running_loss_t += loss_t.item() * batch_size_cur\n","\n","    epoch_loss   = running_loss   / len(train_loader.dataset)\n","    epoch_loss_y = running_loss_y / len(train_loader.dataset)\n","    epoch_loss_t = running_loss_t / len(train_loader.dataset)\n","\n","    print(f\"[Epoch {epoch:03d}] \"\n","          f\"Total: {epoch_loss:.4f} | \"\n","          f\"Y_loss: {epoch_loss_y:.4f} | \"\n","          f\"T_loss: {epoch_loss_t:.4f}\")"],"metadata":{"id":"ui85ueXIi8L1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================\n","# 7. 추론: ITE, ATE 계산\n","# ==============================\n","\n","model.eval()\n","ite_list = []\n","y0_list = []\n","y1_list = []\n","t_list  = []\n","y_true_list = []\n","\n","with torch.no_grad():\n","    for xb, tb, yb in test_loader:\n","        xb = xb.to(device)\n","        y0_pred, y1_pred, p_pred = model(xb)\n","\n","        ite = (y1_pred - y0_pred).cpu().numpy()\n","        y0_list.append(y0_pred.cpu().numpy())\n","        y1_list.append(y1_pred.cpu().numpy())\n","        ite_list.append(ite)\n","        t_list.append(tb.numpy())\n","        y_true_list.append(yb.numpy())\n","\n","ite_array = np.vstack(ite_list)\n","y0_array  = np.vstack(y0_list)\n","y1_array  = np.vstack(y1_list)\n","t_array   = np.vstack(t_list)\n","y_true_array = np.vstack(y_true_list)\n","\n","# 개별 ITE 평균 = 추정된 ATE\n","ate_est = ite_array.mean()\n","print(\"\\n========================\")\n","print(\"Estimated ATE (mean ITE):\", ate_est)\n","print(\"========================\")\n","\n","# 추출값을 CSV로 저장\n","out_df = pd.DataFrame({\n","    \"ITE_hat\": ite_array.flatten(),\n","    \"T\": t_array.flatten(),\n","    \"Y_true\": y_true_array.flatten(),\n","    \"Y1_hat\": y1_array.flatten(),\n","    \"Y0_hat\": y0_array.flatten()\n","})\n","out_df.to_csv(\"dragonnet_ITE_results.csv\", index=False)\n","print(\"Saved ITE results to dragonnet_ITE_results.csv\")"],"metadata":{"id":"AosO6aOCi91n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==============================\n","# 전체 고객 ITE 계산\n","# ==============================\n","all_ds = CausalDataset(X_scaled, t, y)\n","all_loader = DataLoader(all_ds, batch_size=256, shuffle=False)\n","\n","model.eval()\n","ite_list = []\n","y0_list = []\n","y1_list = []\n","t_list  = []\n","y_true_list = []\n","\n","with torch.no_grad():\n","    for xb, tb, yb in all_loader:\n","        xb = xb.to(device)\n","        y0_pred, y1_pred, p_pred = model(xb)\n","\n","        ite = (y1_pred - y0_pred).cpu().numpy()\n","        y0_list.append(y0_pred.cpu().numpy())\n","        y1_list.append(y1_pred.cpu().numpy())\n","        ite_list.append(ite)\n","        t_list.append(tb.numpy())\n","        y_true_list.append(yb.numpy())\n","\n","ite_array = np.vstack(ite_list)\n","y0_array  = np.vstack(y0_list)\n","y1_array  = np.vstack(y1_list)\n","t_array   = np.vstack(t_list)\n","y_true_array = np.vstack(y_true_list)\n","\n","# 전체 ATE\n","ate_est = ite_array.mean()\n","print(\"ATE (전체):\", ate_est)\n","\n","# CSV 저장\n","out_df = pd.DataFrame({\n","    \"ITE_hat\": ite_array.flatten(),\n","    \"T\": t_array.flatten(),\n","    \"Y_true\": y_true_array.flatten(),\n","    \"Y1_hat\": y1_array.flatten(),\n","    \"Y0_hat\": y0_array.flatten()\n","})\n","out_df.to_csv(\"dragonnet_ITE_results_full.csv\", index=False)\n","print(\"Saved FULL ITE results (N =\", len(out_df), \")\")\n"],"metadata":{"id":"fPKCbAT4i_jl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# 1) 입력 변수 X_scaled 저장\n","X_df = pd.DataFrame(X_scaled, columns=[\n","    \"PERIOD_M\",\n","    \"AVG_36_M\",\n","    \"AVG_12_M\",\n","    \"USE_CNT_18Y\",\n","    \"USE_AMT_18Y1\",\n","    \"CNT_18Y\",\n","    \"CNT_18Y_OLV\",\n","    \"MSG0\",\"MSG1\",\"MSG2\",\"MSG3\",\"MSG4\",\"MSG5\",\n","    \"Weekend\",\"Badair\"\n","])\n","\n","# 2) Treatment & Outcome\n","T_df = pd.DataFrame({\"T\": t})\n","Y_df = pd.DataFrame({\"Y_true\": y})\n","\n","# 3) DragonNet 추론값 (이미 너가 만든 변수 이용)\n","ITE_df = pd.DataFrame(ite_array, columns=[\"ITE_hat\"])\n","Y1_df  = pd.DataFrame(y1_array,  columns=[\"Y1_hat\"])\n","Y0_df  = pd.DataFrame(y0_array,  columns=[\"Y0_hat\"])\n","\n","# 4) 모든 변수 병합\n","df_all = pd.concat([X_df, T_df, Y_df, Y1_df, Y0_df, ITE_df], axis=1)\n","\n","# 5) CSV 저장\n","df_all.to_csv(\"dragonnet_full_dataset_for_R_SHAP.csv\", index=False)\n","\n","print(\"Saved dragonnet_full_dataset_for_R_SHAP.csv successfully!\")\n","print(\"Final shape:\", df_all.shape)\n"],"metadata":{"id":"wG5QC2wnjCOO"},"execution_count":null,"outputs":[]}]}